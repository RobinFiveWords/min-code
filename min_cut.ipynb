{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb988be-ae37-446d-9812-2f14ab00c23d",
   "metadata": {},
   "source": [
    "# Min-Code: How little code will suffice to write min-cut from scratch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172f942-3000-40ca-a349-05a42bcb22a8",
   "metadata": {},
   "source": [
    "## 2024-08-26: Intro\n",
    "\n",
    "<a href=\"https://adventofcode.com/2023/day/25\">Day 25</a> of <a href=\"https://adventofcode.com/2023\">Advent of Code 2023</a> describes a highly-interconnected network that can be split in two by cutting three specific wires. Our main job is to identify those three wires. This is known as finding a <a href=\"https://en.wikipedia.org/wiki/Minimum_cut\">minimum cut</a>.\n",
    "\n",
    "When a simple algorithm is needed, I often like to write it from scratch each time, using only built-ins and standard libraries. (Inspirations include the <a href=\"https://www.reddit.com/r/adventofcode/\">Advent of Code subreddit</a>, <a href=\"https://github.com/norvig/pytudes#pytudes-index-of-jupyter-ipython-notebooks\">Peter Norvig</a>, and <a href=\"https://www.youtube.com/watch?v=j6VSAsKAj98\">David Beazley</a>.) By the sixth or seventh time I wrote a breadth-first search, I did it without any conscious doubt about how I was doing it. But that was BFS.\n",
    "\n",
    "I read about maxflows and mincuts in Sedgewick's <a href=\"https://algs4.cs.princeton.edu/\">Algorithms</a>. Their Java code for maxflow problems includes several classes but is quite general. Some classes contain many attributes and methods that I wouldn't need to solve Day 25. I wondered whether I could simplify Sedgewick's approach enough to rewrite it from scratch, in Python, and still get a decent night's sleep. My main problem was that I didn't really understand the <a href=\"https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm\">Ford–Fulkerson algorithm</a>, and how to identify the residual network in Sedgewick's implementation so as to find a minimum cut. As of starting this project, I still don't.\n",
    "\n",
    "Instead, to collect the last of my 50 stars that night — disclaimer: it was January 30, not December 24 — I took a brute-force approach and eventually came up with a simplifying assumption that, although not guaranteed to produce the correct answer, did so in under ten seconds runtime. A few months later, I used <a href=\"https://networkx.org/documentation/stable/\">NetworkX</a> to write an almost trivial solution to the problem, letting the `minimum_edge_cut` and `connected_components` functions do the hard work. NetworkX seems pretty great, and there's probably no reason to avoid using it if I'm already working in Python.\n",
    "\n",
    "But now it's time to return to my original objective. Can I simplify min-cut enough so that I can write it from scratch as needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead05492-5460-4288-9595-589f1f570144",
   "metadata": {},
   "source": [
    "## 2024-08-27: Initial solution\n",
    "\n",
    "Before diving any deeper, I'll describe a cleaned-up version of my <a href=\"https://github.com/RobinFiveWords/AdventOfCode/blob/main/2023/day25.py\">initial solution</a>. If we accept that our starting graph (network) has just one connected component — from any given vertex we can reach every other vertex — then we can test any potential solution by removing its three edges (wires) from the graph and rechecking whether, in this modified graph, from any given vertex we can reach every other vertex. To check the modified graph, we can arbitrarily pick a vertex and do a depth-first search, counting how many vertices we reach. If it is less than the total number of vertices, we have our solution.\n",
    "\n",
    "I couldn't just brute-force it. My puzzle input had 1,514 vertices connected by 3,385 edges, meaning I would potentially have to test\n",
    "$$\n",
    "\\frac{3{,}385 \\times 3{,}384 \\times 3{,}383}{3 \\times 2 \\times 1} = 38{,}751{,}723{,}720 \\nonumber\n",
    "$$\n",
    "combinations of three edges. So I looked for a way to reduce the number of possible solutions I would consider.\n",
    "\n",
    "The assumption I came up with was that the three edges in the solution would connect vertices — let's call these the solution vertices — that were \"closer\" to all other vertices, on average, than most other vertices were. In other words, if for any given vertex I added up the shortest number of edges that would need to be traversed to reach each other vertex, the solution vertices would be among the vertices with the lowest sums.\n",
    "\n",
    "For my reasoning, let's consider one of the edges in the solution to be $X{\\textendash}Y$, connecting vertices $X$ and $Y$. In the modified graph, let's say $X$ is in connected component $A$, and $Y$ is in connected component $B$. We still want to focus on the original, connected graph, but with each vertex belonging to either $A$ or $B$. Now let's consider all the vertices in $A$ other than $X$ for which $X{\\textendash}Y$ is the closest solution edge. For these vertices in $A$, their shortest path to reach any vertex in $B$ is through $X$, which means they are farther from every vertex in $B$ than $X$ is. If $X$ is closer to many other vertices than many others are, perhaps on average it is closer to _all_ other vertices than _most_ others are.\n",
    "\n",
    "For each vertex, I did a breadth-first search to compute the sum of its distances from each other vertex. I then identified any edge in the graph whose vertices were both among the 100 with the lowest total distance. There were 105 such edges, meaning I would only have to test\n",
    "$$\n",
    "\\frac{105 \\times 104 \\times 103}{3 \\times 2 \\times 1} = 187{,}460 \\nonumber\n",
    "$$\n",
    "combinations of three edges. One of these turned out to be the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243849e-42ff-4091-ba87-5de2fa5f67db",
   "metadata": {},
   "source": [
    "## 2024-08-28: Test graph\n",
    "\n",
    "I'm not going to understand this unless I draw an example and carry out the algorithm by hand. I decided to try using the Day 25 test example, which has 15 vertices and 33 edges. This may turn out to be too large to learn on, but I'm hoping that its complexity will help me test my conclusions.\n",
    "\n",
    "I started by drawing the test graph by hand, to see whether I would have any layout issues.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240828_1.jpeg\"\n",
    "        style=\"max-height:400px\"\n",
    "        alt=\"Hand-drawn graph with 15 vertices and 33 edges.\" />\n",
    "</div>\n",
    "\n",
    "This looked pretty good, so I created a cleaner version in <a href=\"https://app.diagrams.net/\">draw.io</a>:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240828_2.png\"\n",
    "        alt=\"Same graph created with draw.io.\" />\n",
    "</div>\n",
    "\n",
    "Shortly after, I realized that I didn't know how to add a source and a sink to turn the graph into a flow network. After a lot of research, I came across <a href=\"https://math.stackexchange.com/questions/744276/minimum-cut-algorithm-on-undirected-graph-with-no-source-or-sink\">my exact question</a> on Stack Exchange. The answer seems to be to pick any vertex as the sink, and then for each other vertex, compute the maxflow with that vertex as the source. Any of the results with the smallest maxflow will lead to a minimum cut."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "753fd3bd-ed63-4c89-aa86-3c95c5f256df",
   "metadata": {},
   "source": [
    "## 2024-08-29: First case\n",
    "\n",
    "I'll turn the test graph into a flow network by choosing one vertex as the source and another as the sink. For more than a day, my curiosity has been nagging me with the question of how to find the _first_ path between the source and the sink. I'm going to leave that unexplored for now — if I'm not mistaken, it will follow the same rules as how to find an _augmenting path_ for any in-progress state of the network. I want to understand what the next step is for at least a few in-progress cases:\n",
    "\n",
    "- The first path snakes through all of the solution edges, so that finding a maxflow will require reversing the flow across one of the solution edges.\n",
    "- The first path crosses exactly one solution edge; the source and sink are in different components of the modified graph.\n",
    "- The source and sink are in the same component, are connected by an edge, and the first path simply traverses that edge.\n",
    "\n",
    "I felt that this last case would be the best starting example, and I chose `qnr` as the source and `frs` as the sink.\n",
    "\n",
    "Sidebar on a maximum flow's upper limit: In an unweighted graph, the maximum flow is at most the number of edges coming out of the source, and also at most the number of edges going into the sink. In a weighted graph, it's the total capacity of those edges.\n",
    "\n",
    "`qnr` has four edges coming out, and `frs` has four edges going in. The maximum flow from `qnr` to `frs` is indeed 4, with the following paths as one possibility:\n",
    "\n",
    "```\n",
    "qnr - frs\n",
    "qnr - rzs - rsh - frs\n",
    "qnr - cmg - lhk - frs\n",
    "qnr - nvd - pzl - lsr - frs\n",
    "```\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240829_1.png\"\n",
    "        alt=\"Test graph with source qnr, sink frs, and the four paths indicated in the text.\" />\n",
    "</div>\n",
    "\n",
    "The first case I wanted to consider is where the first three paths have already been added to the flow network, but `qnr - nvd - pzl - lsr - frs` has not:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240829_2.png\"\n",
    "        alt=\"Test graph with source qnr, sink frs, and the first three of the paths indicated in the text.\" />\n",
    "</div>\n",
    "\n",
    "And the question is, how do I find an augmenting path for this flow network in this state?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e92c11d8-c1a9-4d8b-8926-891960e1c76d",
   "metadata": {},
   "source": [
    "## 2024-08-30: Backward edges\n",
    "\n",
    "A lightbulb finally went on above my head, about three minutes into <a href=\"https://www.youtube.com/watch?v=Tl90tNtKvxs\">this video</a>:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240830_1.png\"\n",
    "        style=\"max-height:400px\"\n",
    "        alt=\"Screenshot from YouTube video where augmenting path is highlighted.\" />\n",
    "</div>\n",
    "\n",
    "It was clear to me that DFS or BFS would always identify an augmenting path, if one existed, using the original flow network — forward edges only — or, in other words, using remaining capacity without undoing any previous flows. But I didn't understand how the use of backward edges would work, as this would undo a previous flow. In the graph above, $A{\\rightarrow}D$ is a forward edge, and $D{\\rightarrow}A$ is a backward edge. The path $S{\\rightarrow}C{\\rightarrow}D{\\rightarrow}A{\\rightarrow}B{\\rightarrow}T$ removes 4 from $A{\\rightarrow}D$, and what I struggled to understand was how removing 4 here, and adding back that same 4 somewhere else, would result in a net increase instead of no net change.\n",
    "\n",
    "I finally realized that a new path using a backward edge is equivalent to the new path saying to the existing path, \"I've got this covered. From my own sources I can send into this vertex up to X of what you sent into this vertex. Take back as much of that X as you can, and try a different route. If any of it can reach the sink, we've found an augmenting path.\"\n",
    "\n",
    "I now realized that my first case is perhaps overly simple, because it can be solved without using any backward paths. Still, I drew the residual network for this network after the first three paths. Because a currently unused edge can be used in either direction — this is an undirected graph — the graph and the residual network include a forward edge in each direction, for any currently unused edge. I've represented unused edges with an arrow at both ends, but the picture would be clearer if I found a way to display two separate arrows, one pointing in either direction.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240830_2.png\"\n",
    "        alt=\"Residual network for test graph after first three paths.\" />\n",
    "</div>\n",
    "\n",
    "The only edge in the residual network coming out of `qnr` goes to `nvd`, so this would be the first edge traversed by any augmenting path. There are four ways to continue from there, and each can produce an augmenting path. The \"I've got this\" approach makes me more comfortable with why that is so. For example, the augmenting path `qnr - nvd - lhk - cmg - rzs - lsr - frs` can be thought of as saying to `qnr - cmg - lhk - frs`, \"I've got `lhk - frs` covered. Change your path to `qnr - cmg - rzs - lsr - frs`. (And I'll be `qnr - nvd - lhk - frs`. And `cmg - lhk` will go back to being unused.)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b33c1a-a3f0-4905-ba47-7728498cf5b5",
   "metadata": {},
   "source": [
    "## 2024-08-31 Undirected edges\n",
    "\n",
    "I feel I'm getting closer to deciding on actual data structures, although I haven't yet specified everything I need those data structures to do. One question I don't know the answer to involves how to handle the two directions of an undirected edge.\n",
    "\n",
    "I'm not sure how to describe this without using weights, so I'll use weights. Let's say edge $A \\textendash B$ has capacity 5, and in the current state $A{\\rightarrow}B$ has flow 2. I initially expected the residual network to show $A{\\rightarrow}B$ with capacity 3 (this is inarguably correct) and $B{\\rightarrow}A$ with capacity 2. But if the maxflow requires a positive flow $B{\\rightarrow}A$, that can't be accomplished with a single augmenting path if the residual network's capacity for $B{\\rightarrow}A$ is only enough to set the true flow back to zero. It makes more sense to me for the residual network's capacity for $B{\\rightarrow}A$ to be 7.\n",
    "\n",
    "Here's a small example of the same concept:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"img/20240831_1.png\"\n",
    "        alt=\"Minimal example with four vertices to demonstrate having to reverse a flow from an existing path; showing the initial undirected graph, first augmenting path, and residual graph.\" />\n",
    "</div>\n",
    "\n",
    "Sidebar on backward edges involving source or sink: I don't think the residual network needs to show any capacity going back into the source or coming out of the sink, which is why I put the two zeros in the residual network graph. This feels intuitive to me, but I also have an explanation for it. The source has infinite capacity, even if the edges do not, so there's nothing to gain by telling the source to try a different route. The source already uses its infinite capacity to try different routes, to try to find augmenting paths. As for the sink, the goal is to flow into the sink. At that point there's nothing to gain by moving backward, because the flow can't do any better than having reached the sink.\n",
    "\n",
    "Back to the example: If the residual network's capacity for $B{\\rightarrow}A$ was limited to the used capacity on $A{\\rightarrow}B$ — 1 rather than 2 — it would take two more augmenting paths to arrive at the maximum flow. The first $S{\\rightarrow}B{\\rightarrow}A{\\rightarrow}T$ would add 1. Then I'd need to observe that $A{\\textendash}B$ was empty and add both $A{\\rightarrow}B$ and $B{\\rightarrow}A$ back to the residual network, each with capacity 1. Finally I could traverse $S{\\rightarrow}B{\\rightarrow}A{\\rightarrow}T$ again to add another 1.\n",
    "\n",
    "So the approach I'm thinking of is to ensure that, for any undirected edge $A{\\textendash}B$, in the residual network the sum of the capacities for $A{\\rightarrow}B$ and $B{\\rightarrow}A$ is constant at twice the capacity of $A{\\textendash}B$. If we add flow to $A{\\rightarrow}B$, we subtract that amount from the residual capacity of $A{\\rightarrow}B$ and add that amount to the residual capacity of $B{\\rightarrow}A$.\n",
    "\n",
    "At this point I wondered how I would handle a case where a solution edge is not full. A little searching gave me the answer that the edges of a minimum cut will always be saturated, that this case doesn't exist. As I thought about it, it dawned on me that if I drew a graph to represent this case, and then found its actual minimum cut, the unsaturated edge that I had in mind would not actually be a solution edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26a60c-03c6-42a5-a842-3117f7ed9e35",
   "metadata": {},
   "source": [
    "## 2024-09-01: Shortest augmenting path\n",
    "\n",
    "I was finally ready to think through and adapt Sedgewick's implementation of searching for an augmenting path. If I understand correctly, this is the Edmonds–Karp method, which Sedgewick describes as \"breadth-first search (BFS) in the residual network\".\n",
    "\n",
    "1. I will need the adjacency list for the residual network.\n",
    "2. I will need the current graph of the residual network.\n",
    "3. For each vertex $B$ other than the source that I come across, I will need the vertex $A$ for which $A{\\rightarrow}B$ is the first potential edge to $B$ I identify, and I will need the capacity of $A{\\rightarrow}B$ in the residual network. I'll call this data structure $D$ for now, and its identifiers will be the $B$ vertex, the vertex the edge goes _to_.\n",
    "4. In each round, for each vertex $A$; for each vertex $B$ on the residual adjacency list for $A$; if $B$ is not yet in $D$ and the residual capacity of $A{\\rightarrow}B$ is greater than zero, I will add $B$ to $D$ and record the edge's $A$ vertex and capacity, and I will include $B$ in the list of vertices to process (in the $A$ role) in the next round.\n",
    "5. The source will be the only vertex $A$ in the first round.\n",
    "6. Rounds will continue until the sink is reached or no vertices are identified for the next round.\n",
    "7. If the process ends without the sink being reached, there is no augmenting path, and the residual network is in its final state.\n",
    "8. Otherwise, I will use $D$ to retrace the path from the sink to the source, recording all edges and capacities.\n",
    "9. I will identify the minimum capacity for the augmenting path.\n",
    "10. I will update the residual network by subtracting the minimum capacity from each edge in the path and adding the minimum capacity to each reversed edge.\n",
    "\n",
    "I feel like the code I eventually write may be simpler and clearer. In Python steps 3 through 6 above might look like this:\n",
    "\n",
    "```python\n",
    "D = {}\n",
    "current_round = [source]\n",
    "next_round = set()\n",
    "while current_round:\n",
    "    for A in current_round:\n",
    "        for B in residual_adj[A]:\n",
    "            if B not in D:\n",
    "                capacity = residual_edges.get((A, B), 0)\n",
    "                if capacity > 0:\n",
    "                    D[B] = (A, capacity)\n",
    "                    next_round.add(B)\n",
    "    if sink in D:\n",
    "        break\n",
    "    current_round = list(next_round)\n",
    "    next_round = set()\n",
    "```\n",
    "\n",
    "I am a bit uneasy at leaving the original flow network behind and working only with the residual network. The justification for this may be that the starting residual network _is_ the original flow network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b94af-8210-4e9c-9754-a70b13bc7c1b",
   "metadata": {},
   "source": [
    "## 2024-09-02 Minimum cut\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c894b61-4d33-4d15-9b1d-b098d9c4b699",
   "metadata": {},
   "source": [
    "For a given source and sink, after finding the residual graph of the maximum flow, to find the mincut I took the approach in <a href=\"https://stackoverflow.com/questions/4482986/how-can-i-find-the-minimum-cut-on-a-graph-using-a-maximum-flow-algorithm/43210670#43210670\">this answer by MichalH</a>. Going back a few days, I chose an arbitrary vertex as the sink and, testing each other vertex as the source, tracked the smallest cutset.\n",
    "\n",
    "I decided the only data structure I needed was an adjacency list that stored the capacity for each edge. In Python I used a nested dictionary, which for the small example looks like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'S': {'A': 1, 'B': 2},\n",
    "    'A': {'S': 1, 'B': 1, 'T': 2},\n",
    "    'B': {'S': 2, 'A': 1, 'T': 1},\n",
    "    'T': {'A': 2, 'B': 1},\n",
    "}\n",
    "```\n",
    "\n",
    "I also used a timer function as a decorator, so I could compare with NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a619c63-cd33-478f-97ff-81ad3768d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from functools import wraps\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df196e6-bc9b-4a4c-bb5e-f7d1c98d22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*arg, **kw):\n",
    "        start = time.time()\n",
    "        result = func(*arg, **kw)\n",
    "        duration = time.time() - start\n",
    "        print('Time for {0}: {1} seconds'\n",
    "              .format(func.__name__, round(duration, 1)))\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15b2ae2-4c27-4e11-93ae-26df8fbca25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def minimum_cut(adjacency_with_capacity):\n",
    "    cutset = None\n",
    "    sink = list(adjacency_with_capacity)[-1]\n",
    "    for source in [v for v in adjacency_with_capacity if v != sink]:\n",
    "        R = deepcopy(adjacency_with_capacity)\n",
    "        while True:\n",
    "            # find augmenting path with Edmonds–Karp\n",
    "            D = {}\n",
    "            current_round = [source]\n",
    "            next_round = set()\n",
    "            while current_round:\n",
    "                for A in current_round:\n",
    "                    for B, capacity in R[A].items():\n",
    "                        if B not in D and capacity > 0:\n",
    "                            D[B] = (A, capacity)\n",
    "                            next_round.add(B)\n",
    "                if sink in D:\n",
    "                    break\n",
    "                current_round = list(next_round)\n",
    "                next_round = set()\n",
    "            if sink not in D:\n",
    "                break  # no augmenting path\n",
    "            # update residual network\n",
    "            minimum_capacity = float('inf')\n",
    "            edges = []\n",
    "            B = sink\n",
    "            A, capacity = D[B]\n",
    "            while True:  # do while A != source\n",
    "                minimum_capacity = min(minimum_capacity, capacity)\n",
    "                edges.append((A, B))\n",
    "                if A == source:\n",
    "                    break\n",
    "                next_A, next_capacity = D[A]\n",
    "                B, A, capacity = A, next_A, next_capacity\n",
    "            for A, B in edges:\n",
    "                R[A][B] -= minimum_capacity\n",
    "                R[B][A] += minimum_capacity\n",
    "        # find reachable vertices with BFS\n",
    "        visited = set()\n",
    "        visited.add(source)\n",
    "        current_vertices = [source]\n",
    "        next_vertices = set()\n",
    "        while current_vertices:\n",
    "            for A in current_vertices:\n",
    "                for B, capacity in R[A].items():\n",
    "                    if B not in visited and capacity > 0:\n",
    "                        visited.add(B)\n",
    "                        next_vertices.add(B)\n",
    "            current_vertices = list(next_vertices)\n",
    "            next_vertices = set()\n",
    "        # find current cutset\n",
    "        current_cutset = [(A, B)\n",
    "                          for A in visited\n",
    "                          for B in adjacency_with_capacity[A]\n",
    "                          if A in visited\n",
    "                          and B not in visited]\n",
    "        if cutset is None or len(current_cutset) < len(cutset):\n",
    "            cutset = current_cutset\n",
    "    return cutset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19bb7c-5633-45ca-9e6f-49f1987cc1e8",
   "metadata": {},
   "source": [
    "I ran it on the Day 25 test case. After fixing a few bugs, it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f834ecc-bad2-491a-b38b-d15d43b97966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd3f289-92b7-423e-8c74-9e8fa33fa6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_awc_from_aoc_input(s):\n",
    "    awc = defaultdict(dict)\n",
    "    for line in s.strip().split('\\n'):\n",
    "        tokens = line.replace(':', '').split()\n",
    "        A = tokens[0]\n",
    "        for B in tokens[1:]:\n",
    "            awc[A][B] = 1\n",
    "            awc[B][A] = 1\n",
    "    return awc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ebbe5e-9a01-4fa6-9990-55465155b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"\n",
    "jqt: rhn xhk nvd\n",
    "rsh: frs pzl lsr\n",
    "xhk: hfx\n",
    "cmg: qnr nvd lhk bvb\n",
    "rhn: xhk bvb hfx\n",
    "bvb: xhk hfx\n",
    "pzl: lsr hfx nvd\n",
    "qnr: nvd\n",
    "ntq: jqt hfx bvb xhk\n",
    "nvd: lhk\n",
    "lsr: lhk\n",
    "rzs: qnr cmg lsr rsh\n",
    "frs: qnr lhk lsr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b89009-d2b0-452a-b321-25041b8da49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_awc = get_awc_from_aoc_input(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48df50ff-cfe3-458b-bc54-5e50d91bafec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for minimum_cut: 0.0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hfx', 'pzl'), ('jqt', 'nvd'), ('bvb', 'cmg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_cut(test_awc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430eb99-a73e-4de2-8dd3-7aeb47a83cec",
   "metadata": {},
   "source": [
    "Now it was time to try the full input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d936df87-9bb8-4293-9f07-c1152bdbcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../AdventOfCode/2023/adventofcode.com_2023_day_25_input.txt') as f:\n",
    "    real_input = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd16d2a-6a0f-4e46-b38a-ef061b6194e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_awc = get_awc_from_aoc_input(real_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878852a6-e8a8-4c8f-8e72-9fb5632b9f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for minimum_cut: 18.1 seconds\n"
     ]
    }
   ],
   "source": [
    "real_mincut = minimum_cut(real_awc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4159e0b-1a27-423e-9d7d-08c924ec1b90",
   "metadata": {},
   "source": [
    "And compare with NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6292322-3bc2-4249-9fb9-3c73621182d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.connectivity import minimum_edge_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b3f8c6-cd9e-4831-a338-a7c28fcf529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def mincut_networkx(s):\n",
    "    G = nx.Graph()\n",
    "    for line in s.strip().split('\\n'):\n",
    "        tokens = line.replace(':', '').split()\n",
    "        A = tokens[0]\n",
    "        for B in tokens[1:]:\n",
    "            G.add_edge(A, B, capacity=1)\n",
    "    return minimum_edge_cut(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2abdf8a8-e7db-4a23-a3c4-49ba6d6d85de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for mincut_networkx: 6.5 seconds\n"
     ]
    }
   ],
   "source": [
    "real_mincut_nx = mincut_networkx(real_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0bb476-00bd-4389-a9d7-66122a2cb3b5",
   "metadata": {},
   "source": [
    "The solutions matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1605ac30-f2de-451e-b2d2-2033bd9c2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted(sorted(edge) for edge in real_mincut) \\\n",
    "    == sorted(sorted(edge) for edge in real_mincut_nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066183a-8ca0-44c1-a86f-6aebf1a8aaf2",
   "metadata": {},
   "source": [
    "I was really happy with this. In not much more than 50 lines of code, using simple data structures, I implemented an algorithm that I had struggled on and off for months to understand. Without any optimization, on this decently-sized graph, it took only about three times as long to run as NetworkX.\n",
    "\n",
    "Could I make my `minimum_cut` function any more concise? Maybe a little, although I'm not playing code golf here. I already used list comprehensions and `defaultdict` for brevity's sake. I could save a line with `visited = set([source])`, but that is a Python-specific workaround for set creation, and reading it confuses me. I also don't think I could cut out much code by assuming an unweighted graph, as I would still need a way to track which edges were full. Tracking capacity achieves this without much overhead.\n",
    "\n",
    "Could I rewrite this completely from scratch, without looking up anything? Maybe after a couple of attempts. I now understand how the algorithm is built from pieces I was already comfortable with.\n",
    "\n",
    "I ran one more test with a truly weighted graph. Sedgewick provided <a href=\"https://algs4.cs.princeton.edu/43mst/mediumEWG.txt\">data</a> for a weighted graph with 250 vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f96a2be-2939-48d6-b2c6-f948d5994568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal  # no floating-point errors for me today, thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed82c96-3c87-47cd-b2ba-a658111243b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mediumEWG.txt') as f:\n",
    "    weighted_input = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc28645-d95c-4031-aff9-febd44ad3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_awc = defaultdict(dict)\n",
    "for line in weighted_input.strip().split('\\n')[2:]:\n",
    "    A, B, weight = line.split()\n",
    "    weighted_awc[A][B] = Decimal(weight)\n",
    "    weighted_awc[B][A] = Decimal(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3bf1f17-d597-4517-9ba5-dce467e19a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for minimum_cut: 3.5 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('25', '111'), ('60', '111')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_mincut = minimum_cut(weighted_awc)\n",
    "weighted_mincut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de240b45-d06c-4736-86d0-a288284716de",
   "metadata": {},
   "source": [
    "There's no reason to expect a unique minimum cut for this graph. Looking back at my implementation, it would be straightforward to accumulate all minimum cuts of smallest size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033974b7-eee4-4414-8ea2-c9181789c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def minimum_cuts(adjacency_with_capacity):\n",
    "    cutsets = set()                                # changed to set\n",
    "    size = None                                    # tracking best size\n",
    "    sink = list(adjacency_with_capacity)[-1]\n",
    "    for source in [v for v in adjacency_with_capacity if v != sink]:\n",
    "        R = deepcopy(adjacency_with_capacity)\n",
    "        while True:\n",
    "            # find augmenting path with Edmonds–Karp\n",
    "            D = {}\n",
    "            current_round = [source]\n",
    "            next_round = set()\n",
    "            while current_round:\n",
    "                for A in current_round:\n",
    "                    for B, capacity in R[A].items():\n",
    "                        if B not in D and capacity > 0:\n",
    "                            D[B] = (A, capacity)\n",
    "                            next_round.add(B)\n",
    "                if sink in D:\n",
    "                    break\n",
    "                current_round = list(next_round)\n",
    "                next_round = set()\n",
    "            if sink not in D:\n",
    "                break  # no augmenting path\n",
    "            # update residual network\n",
    "            minimum_capacity = float('inf')\n",
    "            edges = []\n",
    "            B = sink\n",
    "            A, capacity = D[B]\n",
    "            while True:  # do while A != source\n",
    "                minimum_capacity = min(minimum_capacity, capacity)\n",
    "                edges.append((A, B))\n",
    "                if A == source:\n",
    "                    break\n",
    "                next_A, next_capacity = D[A]\n",
    "                B, A, capacity = A, next_A, next_capacity\n",
    "            for A, B in edges:\n",
    "                R[A][B] -= minimum_capacity\n",
    "                R[B][A] += minimum_capacity\n",
    "        # find reachable vertices with BFS\n",
    "        visited = set()\n",
    "        visited.add(source)\n",
    "        current_vertices = [source]\n",
    "        next_vertices = set()\n",
    "        while current_vertices:\n",
    "            for A in current_vertices:\n",
    "                for B, capacity in R[A].items():\n",
    "                    if B not in visited and capacity > 0:\n",
    "                        visited.add(B)\n",
    "                        next_vertices.add(B)\n",
    "            current_vertices = list(next_vertices)\n",
    "            next_vertices = set()\n",
    "        # find current cutset                      # changed to tuple which is hashable\n",
    "        current_cutset = tuple(sorted(tuple(sorted((A, B)))\n",
    "                                      for A in visited\n",
    "                                      for B in adjacency_with_capacity[A]\n",
    "                                      if A in visited\n",
    "                                      and B not in visited))\n",
    "        if not cutsets:                            # changed to accumulate best cutsets\n",
    "            cutsets.add(current_cutset)\n",
    "            size = len(current_cutset)\n",
    "        elif len(current_cutset) == size:\n",
    "            cutsets.add(current_cutset)\n",
    "        elif len(current_cutset) < size:\n",
    "            cutsets = set([current_cutset])\n",
    "            size = len(current_cutset)\n",
    "    return cutsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fdd3d2d-f7e9-4f73-ade5-b647cadad4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for minimum_cuts: 3.5 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(('111', '25'), ('111', '60')),\n",
       " (('111', '61'), ('111', '87')),\n",
       " (('127', '20'), ('127', '89'))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_cuts(weighted_awc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d49c29-e7c7-410a-a50a-f677d6374c9a",
   "metadata": {},
   "source": [
    "So that's pretty cool — because I wrote it from scratch, it was straightforward to tweak it to answer this related question.\n",
    "\n",
    "I spent several minutes researching whether NetworkX can do this, and while there is an `all_node_cuts` function, I didn't find an off-the-shelf function to return all minimum edge cuts. To be sure, NetworkX returns one of the solutions in less than one-tenth the time mine did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de389b40-7e73-4274-a999-03af871f8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_graph = nx.Graph()\n",
    "for line in weighted_input.strip().split('\\n')[2:]:\n",
    "    A, B, capacity = line.split()\n",
    "    weighted_graph.add_edge(A, B, capacity=Decimal(capacity))\n",
    "    weighted_graph.add_edge(B, A, capacity=Decimal(capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc2759c2-0860-4b69-93a6-d40b0437076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 210 ms, sys: 3.54 ms, total: 214 ms\n",
      "Wall time: 214 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('111', '25'), ('111', '60')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "minimum_edge_cut(weighted_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
